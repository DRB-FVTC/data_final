{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analytics Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaner for the food_coded.csv dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are looking to learn about the eating habits of college students. This includes how health conscious they are, how their eating habits have changed since starting college, their preferences related to ethnic food, and what some of their preferences might be related to available selections and pricing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is primarily an exploratory data analysis where we work with a collection of data, clean and format the data, summarize statistics and visualize distributions, examine relationships and create a predictive model, all while addressing inconsistencies in the dataset, handling data that may skew or bias the results of our model, and finding a meaningful insight into how the cafeteria can help improve the eating habits of students. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin our analysis, we will have to make sure the dataset we are working with has been thoroughly cleaned and formatted in such a way that we can effortlessly use python data analysis and visualization libraries on it to produce meaningful models and visualizations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# md repo\n",
    "# <span style=\"color:green\"></span>\n",
    "# <span style=\"color:red\"></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import built in libraries for handling files and data\n",
    "import io\n",
    "import os\n",
    "import random\n",
    "\n",
    "# import library for data analysis\n",
    "import pandas as pd\n",
    "\n",
    "# define constants\n",
    "DATA_FILE_PATH = os.path.join(os.getcwd(), \"material/data\", \"food_coded.csv\")\n",
    "CLEAN_FILE_PATH = os.path.join(os.getcwd(), \"material/data\", \"food_cleaned.csv\")\n",
    "FAST_COLUMN = [\n",
    "    'cook', 'cuisine', 'diet_current', 'drink', 'eating_changes', 'employment', \n",
    "    'exercise', 'father_education', 'father_profession', 'fav_cuisine', \n",
    "    'fav_food', 'food_childhood', 'healthy_meal', 'ideal_diet', 'income', \n",
    "    'life_rewarding', 'marital_status', 'meals_dinner_friend', 'mother_education', \n",
    "    'mother_profession', 'on_off_campus', 'persian_food', 'self_perception_weight', \n",
    "    'soup', 'sports', 'tortilla_calories', 'type_sports', 'weight'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GPA</th>\n",
       "      <th>Gender</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>calories_chicken</th>\n",
       "      <th>calories_day</th>\n",
       "      <th>calories_scone</th>\n",
       "      <th>coffee</th>\n",
       "      <th>comfort_food</th>\n",
       "      <th>comfort_food_reasons</th>\n",
       "      <th>comfort_food_reasons_coded</th>\n",
       "      <th>...</th>\n",
       "      <th>soup</th>\n",
       "      <th>sports</th>\n",
       "      <th>thai_food</th>\n",
       "      <th>tortilla_calories</th>\n",
       "      <th>turkey_calories</th>\n",
       "      <th>type_sports</th>\n",
       "      <th>veggies_day</th>\n",
       "      <th>vitamins</th>\n",
       "      <th>waffle_calories</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>315.0</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>we dont have comfort</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>345</td>\n",
       "      <td>car racing</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.654</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>chocolate, chips, ice cream</td>\n",
       "      <td>Stress, bored, anger</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>725.0</td>\n",
       "      <td>690</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>900</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>4.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>frozen yogurt, pizza, fast food</td>\n",
       "      <td>stress, sadness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>500</td>\n",
       "      <td>none</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>900</td>\n",
       "      <td>I'm not answering this.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pizza, Mac and cheese, ice cream</td>\n",
       "      <td>Boredom</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>725.0</td>\n",
       "      <td>690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>Not sure, 240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>2.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ice cream, chocolate, chips</td>\n",
       "      <td>Stress, boredom, cravings</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>Softball</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>760</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GPA  Gender  breakfast  calories_chicken  calories_day  calories_scone  \\\n",
       "0    2.4       2          1               430           NaN           315.0   \n",
       "1  3.654       1          1               610           3.0           420.0   \n",
       "2    3.3       1          1               720           4.0           420.0   \n",
       "3    3.2       1          1               430           3.0           420.0   \n",
       "4    3.5       1          1               720           2.0           420.0   \n",
       "\n",
       "   coffee                      comfort_food        comfort_food_reasons  \\\n",
       "0       1                              none       we dont have comfort    \n",
       "1       2       chocolate, chips, ice cream        Stress, bored, anger   \n",
       "2       2   frozen yogurt, pizza, fast food             stress, sadness   \n",
       "3       2  Pizza, Mac and cheese, ice cream                     Boredom   \n",
       "4       2      Ice cream, chocolate, chips   Stress, boredom, cravings    \n",
       "\n",
       "   comfort_food_reasons_coded  ...  soup  sports  thai_food tortilla_calories  \\\n",
       "0                         9.0  ...   1.0     1.0          1            1165.0   \n",
       "1                         1.0  ...   1.0     1.0          2             725.0   \n",
       "2                         1.0  ...   1.0     2.0          5            1165.0   \n",
       "3                         2.0  ...   1.0     2.0          5             725.0   \n",
       "4                         1.0  ...   1.0     1.0          4             940.0   \n",
       "\n",
       "   turkey_calories  type_sports veggies_day  vitamins  waffle_calories  \\\n",
       "0              345   car racing           5         1             1315   \n",
       "1              690  Basketball            4         2              900   \n",
       "2              500         none           5         1              900   \n",
       "3              690          NaN           3         1             1315   \n",
       "4              500     Softball           4         2              760   \n",
       "\n",
       "                     weight  \n",
       "0                       187  \n",
       "1                       155  \n",
       "2  I'm not answering this.   \n",
       "3             Not sure, 240  \n",
       "4                       190  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset from csv file\n",
    "food = pd.read_csv(DATA_FILE_PATH)\n",
    "food.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the dataset\n",
    "descript = food.describe()\n",
    "shape = food.shape\n",
    "columns = food.columns\n",
    "nulls = food.isnull().sum()\n",
    "\n",
    "# had to look up had to handle the response from .info\n",
    "buffer = io.StringIO()\n",
    "food.info(buf=buffer)\n",
    "info = buffer.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produceReport(shape, columns, info, descript, nulls, name):\n",
    "\n",
    "    # use name parameter to add a suffix to the file name\n",
    "    suffix = f\"_{name}\" if name in ['raw', 'clean'] else \"\"\n",
    "    \n",
    "    # format string\n",
    "    report = f\"\"\"\n",
    "=======================================\n",
    "FOOD DATA SUMMARY REPORT\n",
    "=======================================\n",
    "\n",
    "* OVERVIEW\n",
    "- **Shape (Rows, Columns):** {shape}\n",
    "- **Columns:** {', '.join(columns)}\n",
    "\n",
    "---------------------------------------\n",
    "\n",
    "* COLUMNS\n",
    "- Data Types and Non-Null Counts:\n",
    "{info}\n",
    "---------------------------------------\n",
    "\n",
    "* DESCRIPTIVE STATISTICS\n",
    "{descript}\n",
    "\n",
    "---------------------------------------\n",
    "\n",
    "* MISSING VALUES\n",
    "- Number of Missing Values Per Column:\n",
    "{nulls.to_string()}\n",
    "\n",
    "=======================================\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "    file_name = f\"material/data_report{suffix}.txt\"\n",
    "\n",
    "    # save file\n",
    "    with open(file_name, \"w\") as file:\n",
    "        file.write(report)\n",
    "        return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a report from the `explore the dataset` cell\n",
    "name = 'raw'\n",
    "file_name = produceReport(shape, columns, info, descript, nulls, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['GPA', 'Gender', 'breakfast', 'calories_chicken', 'calories_day',\n",
      "       'calories_scone', 'coffee', 'comfort_food', 'comfort_food_reasons',\n",
      "       'comfort_food_reasons_coded', 'cook', 'comfort_food_reasons_coded.1',\n",
      "       'cuisine', 'diet_current', 'diet_current_coded', 'drink',\n",
      "       'eating_changes', 'eating_changes_coded', 'eating_changes_coded1',\n",
      "       'eating_out', 'employment', 'ethnic_food', 'exercise',\n",
      "       'father_education', 'father_profession', 'fav_cuisine',\n",
      "       'fav_cuisine_coded', 'fav_food', 'food_childhood', 'fries', 'fruit_day',\n",
      "       'grade_level', 'greek_food', 'healthy_feeling', 'healthy_meal',\n",
      "       'ideal_diet', 'ideal_diet_coded', 'income', 'indian_food',\n",
      "       'italian_food', 'life_rewarding', 'marital_status',\n",
      "       'meals_dinner_friend', 'mother_education', 'mother_profession',\n",
      "       'nutritional_check', 'on_off_campus', 'parents_cook', 'pay_meal_out',\n",
      "       'persian_food', 'self_perception_weight', 'soup', 'sports', 'thai_food',\n",
      "       'tortilla_calories', 'turkey_calories', 'type_sports', 'veggies_day',\n",
      "       'vitamins', 'waffle_calories', 'weight'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# view the columns\n",
    "print(food.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix gender and gpa capitalization\n",
    "food.rename(columns={\"Gender\": \"gender\"}, inplace=True)\n",
    "food.rename(columns={\"GPA\": \"gpa\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">I am happy with the way the columns are named. No changes needed.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           gender   breakfast  calories_chicken  calories_day  calories_scone  \\\n",
      "count  125.000000  125.000000        125.000000    106.000000      124.000000   \n",
      "mean     1.392000    1.112000        577.320000      3.028302      505.241935   \n",
      "std      0.490161    0.316636        131.214156      0.639308      230.840506   \n",
      "min      1.000000    1.000000        265.000000      2.000000      315.000000   \n",
      "25%      1.000000    1.000000        430.000000      3.000000      420.000000   \n",
      "50%      1.000000    1.000000        610.000000      3.000000      420.000000   \n",
      "75%      2.000000    1.000000        720.000000      3.000000      420.000000   \n",
      "max      2.000000    2.000000        720.000000      4.000000      980.000000   \n",
      "\n",
      "          coffee  comfort_food_reasons_coded        cook  \\\n",
      "count  125.00000                  106.000000  122.000000   \n",
      "mean     1.75200                    2.698113    2.786885   \n",
      "std      0.43359                    1.972042    1.038351   \n",
      "min      1.00000                    1.000000    1.000000   \n",
      "25%      2.00000                    2.000000    2.000000   \n",
      "50%      2.00000                    2.000000    3.000000   \n",
      "75%      2.00000                    3.000000    3.000000   \n",
      "max      2.00000                    9.000000    5.000000   \n",
      "\n",
      "       comfort_food_reasons_coded.1     cuisine  ...  persian_food  \\\n",
      "count                    125.000000  108.000000  ...    124.000000   \n",
      "mean                       2.688000    1.388889  ...      2.806452   \n",
      "std                        1.910987    0.974759  ...      1.423824   \n",
      "min                        1.000000    1.000000  ...      1.000000   \n",
      "25%                        2.000000    1.000000  ...      2.000000   \n",
      "50%                        2.000000    1.000000  ...      3.000000   \n",
      "75%                        3.000000    1.000000  ...      4.000000   \n",
      "max                        9.000000    6.000000  ...      5.000000   \n",
      "\n",
      "       self_perception_weight        soup      sports   thai_food  \\\n",
      "count              124.000000  124.000000  123.000000  125.000000   \n",
      "mean                 3.120968    1.217742    1.390244    3.336000   \n",
      "std                  1.115980    0.414385    0.489800    1.436528   \n",
      "min                  1.000000    1.000000    1.000000    1.000000   \n",
      "25%                  2.000000    1.000000    1.000000    2.000000   \n",
      "50%                  3.000000    1.000000    1.000000    3.000000   \n",
      "75%                  4.000000    1.000000    2.000000    5.000000   \n",
      "max                  6.000000    2.000000    2.000000    5.000000   \n",
      "\n",
      "       tortilla_calories  turkey_calories  veggies_day    vitamins  \\\n",
      "count         124.000000       125.000000   125.000000  125.000000   \n",
      "mean          947.580645       555.040000     4.008000    1.512000   \n",
      "std           202.090179       152.370379     1.081337    0.501867   \n",
      "min           580.000000       345.000000     1.000000    1.000000   \n",
      "25%           725.000000       500.000000     3.000000    1.000000   \n",
      "50%           940.000000       500.000000     4.000000    2.000000   \n",
      "75%          1165.000000       690.000000     5.000000    2.000000   \n",
      "max          1165.000000       850.000000     5.000000    2.000000   \n",
      "\n",
      "       waffle_calories  \n",
      "count       125.000000  \n",
      "mean       1073.400000  \n",
      "std         248.667092  \n",
      "min         575.000000  \n",
      "25%         900.000000  \n",
      "50%         900.000000  \n",
      "75%        1315.000000  \n",
      "max        1315.000000  \n",
      "\n",
      "[8 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "# summary statistics\n",
    "print(food.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpa                            2\n",
      "calories_day                  19\n",
      "calories_scone                 1\n",
      "comfort_food                   1\n",
      "comfort_food_reasons           2\n",
      "comfort_food_reasons_coded    19\n",
      "cook                           3\n",
      "cuisine                       17\n",
      "diet_current                   1\n",
      "drink                          2\n",
      "eating_changes                 3\n",
      "employment                     9\n",
      "exercise                      13\n",
      "father_education               1\n",
      "father_profession              3\n",
      "fav_cuisine                    2\n",
      "fav_food                       2\n",
      "food_childhood                 1\n",
      "healthy_meal                   1\n",
      "ideal_diet                     1\n",
      "income                         1\n",
      "life_rewarding                 1\n",
      "marital_status                 1\n",
      "meals_dinner_friend            3\n",
      "mother_education               3\n",
      "mother_profession              2\n",
      "on_off_campus                  1\n",
      "persian_food                   1\n",
      "self_perception_weight         1\n",
      "soup                           1\n",
      "sports                         2\n",
      "tortilla_calories              1\n",
      "type_sports                   26\n",
      "weight                         2\n"
     ]
    }
   ],
   "source": [
    "# show missing data, after each cell below rerun this 'to do list'\n",
    "missing_data = food.isnull().sum()\n",
    "show_missing = missing_data[missing_data > 0]\n",
    "print(show_missing.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "Mean of 'gpa': 3.4155583333333337\n",
      "Median of 'gpa': 3.5\n",
      "Mode of 'gpa': 3.5\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# clean gpa and handle null values\n",
    "food['gpa'] = pd.to_numeric(food['gpa'], errors='coerce')\n",
    "print(food['gpa'].dtype)\n",
    "print(f\"Mean of 'gpa': {food['gpa'].mean()}\")\n",
    "print(f\"Median of 'gpa': {food['gpa'].median()}\")\n",
    "print(f\"Mode of 'gpa': {food['gpa'].mode()[0]}\")\n",
    "\n",
    "# I will use the median/mode value of 3.5 for missing gpa values.\n",
    "food['gpa'] = food['gpa'].fillna(food['gpa'].median())\n",
    "\n",
    "# Last value printed should be '0'\n",
    "print(food['gpa'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "Mean of 'calories_day': 3.0283018867924527\n",
      "Median of 'calories_day': 3.0\n",
      "Mode of 'calories_day': 3.0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# clean calories_day and handle null values\n",
    "food['calories_day'] = pd.to_numeric(food['calories_day'], errors='coerce')\n",
    "print(food['calories_day'].dtype)\n",
    "print(f\"Mean of 'calories_day': {food['calories_day'].mean()}\")\n",
    "print(f\"Median of 'calories_day': {food['calories_day'].median()}\")\n",
    "print(f\"Mode of 'calories_day': {food['calories_day'].mode()[0]}\")\n",
    "\n",
    "# I will use the median/mode value for missing calories_day values.\n",
    "food['calories_day'] = food['calories_day'].fillna(food['calories_day'].median())\n",
    "\n",
    "# Last value printed should be '0'\n",
    "print(food['calories_day'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "Mean of 'calories_scone': 505.241935483871\n",
      "Median of 'calories_scone': 420.0\n",
      "Mode of 'calories_scone': 420.0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# clean calories_scone and handle null values\n",
    "food['calories_scone'] = pd.to_numeric(food['calories_scone'], errors='coerce')\n",
    "print(food['calories_scone'].dtype)\n",
    "print(f\"Mean of 'calories_scone': {food['calories_scone'].mean()}\")\n",
    "print(f\"Median of 'calories_scone': {food['calories_scone'].median()}\")\n",
    "print(f\"Mode of 'calories_scone': {food['calories_scone'].mode()[0]}\")\n",
    "\n",
    "# I will use the median/mode value for missing calories_scone values.\n",
    "food['calories_scone'] = food['calories_scone'].fillna(food['calories_scone'].median())\n",
    "\n",
    "# Last value printed should be '0'\n",
    "print(food['calories_scone'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "Mean of 'weight': 158.5\n",
      "Median of 'weight': 155.0\n",
      "Mode of 'weight': 135.0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# clean weight and handle null values\n",
    "food['weight'] = pd.to_numeric(food['weight'], errors='coerce')\n",
    "print(food['weight'].dtype)\n",
    "print(f\"Mean of 'weight': {food['weight'].mean()}\")\n",
    "print(f\"Median of 'weight': {food['weight'].median()}\")\n",
    "print(f\"Mode of 'weight': {food['weight'].mode()[0]}\")\n",
    "\n",
    "# I will use the median value for missing weight values.\n",
    "food['weight'] = food['weight'].fillna(food['weight'].median())\n",
    "\n",
    "# Last value printed should be '0'\n",
    "print(food['weight'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color:red\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CODE: RETROFIX CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: comfort_food\n",
      "  Missing values: 1\n",
      "  Unique values: 124\n",
      "  Unique values in 'comfort_food': ['none' 'chocolate, chips, ice cream' 'frozen yogurt, pizza, fast food'\n",
      " 'Pizza, Mac and cheese, ice cream' 'Ice cream, chocolate, chips '\n",
      " 'Candy, brownies and soda.'\n",
      " 'Chocolate, ice cream, french fries, pretzels'\n",
      " 'Ice cream, cheeseburgers, chips.' 'Donuts, ice cream, chips'\n",
      " 'Mac and cheese, chocolate, and pasta '\n",
      " 'Pasta, grandma homemade chocolate cake anything homemade '\n",
      " 'chocolate, pasta, soup, chips, popcorn' 'Cookies, popcorn, and chips'\n",
      " 'ice cream, cake, chocolate'\n",
      " 'Pizza, fruit, spaghetti, chicken and Potatoes  '\n",
      " 'cookies, donuts, candy bars' 'Saltfish, Candy and Kit Kat '\n",
      " 'chips, cookies, ice cream' 'Chocolate, ice crea '\n",
      " 'pizza, wings, Chinese' 'Fast food, pizza, subs'\n",
      " 'chocolate, sweets, ice cream' 'burgers, chips, cookies'\n",
      " 'Chilli, soup, pot pie' 'Soup, pasta, brownies, cake'\n",
      " 'chocolate, ice cream/milkshake, cookies'\n",
      " 'Chips, ice cream, microwaveable foods ' 'Chicken fingers, pizza '\n",
      " 'cookies, hot chocolate, beef jerky'\n",
      " 'Tomato soup, pizza, Fritos, Meatball sub, Dr. Pepper'\n",
      " 'cookies, mac-n-cheese, brownies, french fries, '\n",
      " 'chips and dip, pepsi, '\n",
      " \"Grandma's Chinese, Peruvian food from back home, and sushi\"\n",
      " 'Ice cream, cookies,  Chinese food, and chicken nuggets '\n",
      " 'french fries, chips, ice cream'\n",
      " 'mac n cheese, peanut butter and banana sandwich, omelet'\n",
      " 'pizza, doughnuts, mcdonalds ' 'chocolate, chips, candy'\n",
      " 'chocolate, popcorn, ice cream'\n",
      " \"Candy\\rPop\\rChocolate \\rChipotle \\rMoe's \"\n",
      " 'Pizza, Ice cream, fries, cereal, cookies  '\n",
      " 'Ice cream, chocolate, twizzlers '\n",
      " 'ice cream, cookie dough, cookies, cheese'\n",
      " 'ice cream, cereal, and salt and vinegar chips '\n",
      " 'Potato chips, ice cream, chocolate, cookies'\n",
      " 'Mac and cheese, fried chicken, cornbread '\n",
      " 'popcorn, chips, candy, & fries ' 'Chex-mix, Wegmans cookies, Cheez-Its '\n",
      " 'pizza, ice cream, chips'\n",
      " 'fried chicken. mashed potatoes, mac and cheese'\n",
      " 'Popcorn, Chex Mix, Pizza' 'Burger' 'Pizza, chocolate, and ice cream '\n",
      " 'fries, chips, fried chicken, pizza, grapes'\n",
      " 'peanut butter sandwich, pretzals, garlic bread'\n",
      " 'chips, dip, fries, pizza' 'Pizza, Ice Cream, Chicken Wings'\n",
      " 'Pizza chocolate chips bagels ice Capps ' 'Chocolate, ice cream, pasta'\n",
      " 'Mac n Cheese. Chips and salsa. Ice cream. '\n",
      " 'peanut butter, dessets, pretzels. '\n",
      " 'Macaroons, truffles, peanut butter n chocolate ice cream'\n",
      " 'ice cream, cookies, ice cream'\n",
      " 'carrots and ranch, pretzels, dark chocolate '\n",
      " 'cookies, nutella, ice cream, coffee, fruit ' 'mac and cheese'\n",
      " 'Chocolate, Popcorn, Icecream'\n",
      " 'Ice cream, cake, mozzarella sticks, pierogies '\n",
      " 'Chips, Mac and cheese, pizza, French fries '\n",
      " 'Pizza, burritos, slim jims'\n",
      " 'Broccoli, spaghetti squash, quinoa, and grilled chicken'\n",
      " 'Chocolate, ice cream, cookie dough'\n",
      " 'pizza, pretzels, fruit snacks, deli sandwhich' 'Chips, ice cream' nan\n",
      " 'mac and cheese, potato soup, ice cream, chips and cheese'\n",
      " 'chocolate, pizza, and mashed potatoes' 'Pizza cookies steak '\n",
      " 'chocolate, fruit, and ice cream' 'Chips sweets popcorn'\n",
      " 'Cookies, burgers, chicken noodle soup, ice cream'\n",
      " 'cake, French fries, chicken nuggets' 'pizza, ice cream, cookies'\n",
      " 'Mashed potatoes, pasta' 'Pasta dishes, Cheesecake, Pancakes'\n",
      " 'Ice cream, pizza, cookies'\n",
      " 'Chinese food, moes, sponge candy, homemade lasagne '\n",
      " 'pizza, pasta, mac and cheese' 'Little Debbie snacks, donuts, pizza'\n",
      " 'carrots, plantain chips, almonds, popcorn '\n",
      " 'chips, ice cream, fruit snacks'\n",
      " 'Macaroni and cheese, chicken noodle soup, pizza'\n",
      " 'Chocolate, Chips, Ice cream, French Fires, Pizza'\n",
      " 'Mac and cheese, lasagna, Chinese food ' 'candy, Chinese, mcdonalds'\n",
      " 'Doritos, mac and cheese, ice cream'\n",
      " 'Ice cream, cake, pop, pizza, and milkshakes.'\n",
      " 'Mac and Cheese, Pizza, Ice Cream and French Fries ' 'Soup, pasta, cake'\n",
      " 'mac & cheese, frosted brownies, chicken nuggs'\n",
      " 'watermelon, grapes, ice cream'\n",
      " 'macaroni and cheese, stuffed peppers, hamburgers, french fries'\n",
      " 'Pizza, mashed potatoes, spaghetti'\n",
      " \"dark chocolate, terra chips, reese's cups(dark chocolate), and bread/crackers with cottage cheese\"\n",
      " 'Chips, chocolate, ,mozzarella sticks ' 'ice cream, chips, candy'\n",
      " 'Pizza, soda, chocolate brownie, chicken tikka masala and butter naan '\n",
      " 'Chocolate, Pasta, Cookies' 'Candy, salty snacks, toast'\n",
      " 'Mac in cheese, pizza, mozzarella sticks ' 'Ice-cream, pizza, chocolate'\n",
      " 'snacks, chips, ' 'Chocolate, Ice cream, pizza'\n",
      " 'ice cream, pizza, Chinese food ' 'Burgers, indian and korean food\\r'\n",
      " 'chocolate bar, ice cream, pretzels, potato chips and protein bars.'\n",
      " 'Ice cream, chocolate, pizza, cucumber '\n",
      " 'Noodle ( any kinds of noodle), Tuna sandwich, and Egg.\\r'\n",
      " 'Chinese, chips, cake' 'chips, rice, chicken curry,'\n",
      " 'wine. mac and cheese, pizza, ice cream ' 'Pizza / Wings / Cheesecake'\n",
      " 'rice, potato, seaweed soup' 'Mac n Cheese, Lasagna, Pizza'\n",
      " 'Chocolates, pizza, and Ritz.']\n",
      "\n",
      "Column: comfort_food_reasons\n",
      "  Missing values: 2\n",
      "  Unique values: 106\n",
      "  Unique values in 'comfort_food_reasons': ['we dont have comfort ' 'Stress, bored, anger' 'stress, sadness'\n",
      " 'Boredom' 'Stress, boredom, cravings '\n",
      " \"None, i don't eat comfort food. I just eat when i'm hungry.\"\n",
      " 'stress, boredom'\n",
      " 'I eat comfort food when im stressed out from school(finals week), when I`m sad, or when i am dealing with personal family issues.'\n",
      " 'Boredom ' 'Stress, anger and sadness ' 'sadness, stress, cold weather'\n",
      " 'Sadness, boredom, late night snack '\n",
      " 'stress,  boredom, special occasions' 'Friends, environment and boredom'\n",
      " 'boredom' 'Stress '\n",
      " \"I usually only eat comfort food when I'm bored, if i am doing something, i can go for hours without eating \"\n",
      " 'Sadness, stress' 'boredom, sadness, hungry' 'happiness, satisfaction'\n",
      " 'Mostly boredom' 'sadness, depression ' 'Stress and boredom '\n",
      " 'A long day, not feeling well, winter ' 'Boredom, lazyniss '\n",
      " 'survival, bored' 'Boredom, anger, drunkeness'\n",
      " 'stress, boredom, cold weather' 'stres, boredom, and nighttime'\n",
      " 'Hunger and Boredom ' 'boredom, sadness, and if it has a good taste. '\n",
      " 'boredom, stressed, sad' 'Boredom usually' 'Stress' 'boredom, stress'\n",
      " 'No reasons ' \"Usually if I'm sad or depressed. \" 'Tired '\n",
      " 'Boredom!, sadness' 'All of the above; sadness, boredom and confusion '\n",
      " 'Stress, boredom, craving' 'Hunger, boredom' 'sadness, boredom, & anger '\n",
      " 'Boredom, happiness, distraught '\n",
      " 'stressed, upset, or just craving a cheat meal'\n",
      " 'They taste better than other food. They are a pickme up. They are easy to make'\n",
      " 'Stress, boredom' 'Lazy' 'Boredom, sadness and anger ' 'Boredom, sadness'\n",
      " 'stress, anger and boredom' 'bored, stress'\n",
      " 'I usually only eat comfort foods when I am bored. I will also eat them when I am happy to celebrate and then when I am sad to comfort me.'\n",
      " 'Just cause ' 'Stress, boredom, sadness' 'Boredom. Celebration. '\n",
      " 'Sadness, boredom, lonely.'\n",
      " 'I do not really eat \"comfort food\" but I guess sadness, special occasions, and anxiety '\n",
      " 'boredom, sadness' 'sadness' 'Bordem, happiness, sadness'\n",
      " 'Stress, sadness, bored ' 'Boredom, stress, and it tastes good'\n",
      " 'Bad day, bored, sadness'\n",
      " 'Boredom, being in your period, and long bus rides for softball'\n",
      " 'boredom, anger, happy' 'Boredom, stress' nan\n",
      " 'sadness, stressed, boredom' 'boredom and stress'\n",
      " 'Boredom comfort hunger ' 'happiness, hunger, sadness'\n",
      " 'Boredom, sadness, or with friends ' 'Sadness, Loneliness, Boredom'\n",
      " 'Mostly Stress' 'boredom, sadness ' 'when i am sad or craving'\n",
      " 'stress, boredom, college as whole ' 'Boredom and stress'\n",
      " 'Stress, sadness, boredom' 'laziness and hungover'\n",
      " 'Boredom, hunger, snacking.' 'Happiness, sadness, celebration.'\n",
      " 'Boredom, anger and just being hungry in general.'\n",
      " 'Depression, comfort, accessibility '\n",
      " 'they are yummy, my boyfriend sometimes makes me sad, boredom'\n",
      " 'Sad, bored, excited' 'boredom, stress, mood swings' 'Anger, sadness'\n",
      " 'Anxiousness, watching TV I desire \"comfort food\" '\n",
      " 'Boredom, sadness, anxiety' 'Boredom, laziness, anger'\n",
      " 'Stress and sadness'\n",
      " 'I am always stressed out, and bored when I am in my apartment. '\n",
      " 'Stress, frustration, self-consciousness ' 'Sadness and cravings'\n",
      " 'Sadness, happiness and boredom' 'Boredom and sadness'\n",
      " 'sadness, happiness and hunger' 'Stress, boredom and physical activity'\n",
      " 'loneliness, homework, boredom '\n",
      " \"When i'm  eating with my close friends/ Food smell or look good/ when I feel tired\"\n",
      " 'Happiness, boredom, social event' 'boredom and sadness '\n",
      " 'Loneliness / Homesick / Sadness'\n",
      " 'happiness, they are some of my favorite foods'\n",
      " 'hormones, Premenstrual syndrome.']\n",
      "\n",
      "Column: comfort_food_reasons_coded\n",
      "  Missing values: 19\n",
      "  Unique values: 9\n",
      "  Unique values in 'comfort_food_reasons_coded': [ 9.  1.  2.  4.  3.  7.  6.  5.  8. nan]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_comfort = ['comfort_food', 'comfort_food_reasons', 'comfort_food_reasons_coded']\n",
    "\n",
    "for column in check_comfort:\n",
    "    missing_count = food[column].isnull().sum()\n",
    "    unique_values = food[column].nunique()\n",
    "    print(f\"Column: {column}\")\n",
    "    print(f\"  Missing values: {missing_count}\")\n",
    "    print(f\"  Unique values: {unique_values}\")\n",
    "    print(f\"  Unique values in '{column}': {food[column].unique()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# replace null with 'missing' in comfort_food and comfort_food_reasons\n",
    "food['comfort_food'] = food['comfort_food'].fillna('missing')\n",
    "food['comfort_food_reasons'] = food['comfort_food_reasons'].fillna('missing')\n",
    "\n",
    "# replace null with code=9 (None) in comfort_food_reasons_coded\n",
    "food['comfort_food_reasons_coded'] = food['comfort_food_reasons_coded'].fillna(9)\n",
    "\n",
    "# should all print '0'\n",
    "print(food['comfort_food'].isnull().sum())\n",
    "print(food['comfort_food_reasons'].isnull().sum())\n",
    "print(food['comfort_food_reasons_coded'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color:red\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RETROFIXED\n",
    "# clean comfort_food and handle missing values\n",
    "#print(f\"Mode of 'comfort_food': {food['comfort_food'].mode()[0]}\")\n",
    "\n",
    "# create a list to randomly select a mode\n",
    "#modes = food['comfort_food'].mode().tolist()\n",
    "#selected_mode = random.choice(modes)\n",
    "#food['comfort_food'] = food['comfort_food'].fillna(selected_mode)\n",
    "\n",
    "# Last value printed should be '0'\n",
    "#print(food['comfort_food'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">It was at this point I decided it would be smarter (due to time constraints) to just establish ground rules for how I was cleaning, and to include the process in the report because there will be some bias introduced due to the laisse-faire approach of iterating mode imputes for the categorical missing data.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runNullFixer(food, FAST_COLUMN):\n",
    "\n",
    "    for column in FAST_COLUMN:\n",
    "\n",
    "        missing_count = food[column].isnull().sum()\n",
    "\n",
    "        if missing_count <= 12:\n",
    "            print(f\"\\nHandling missing data for '{column}' with {missing_count} missing values.\")\n",
    "            \n",
    "            # Get modes of the column and select a random mode\n",
    "            modes = food[column].mode().tolist()\n",
    "            selected_mode = random.choice(modes)\n",
    "            \n",
    "            # Fill missing values with the selected mode\n",
    "            food[column] = food[column].fillna(selected_mode)\n",
    "\n",
    "            print(f\"After runNullFixer missing values in '{column}': {food[column].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Handling missing data for 'cook' with 3 missing values.\n",
      "After runNullFixer missing values in 'cook': 0\n",
      "\n",
      "Handling missing data for 'diet_current' with 1 missing values.\n",
      "After runNullFixer missing values in 'diet_current': 0\n",
      "\n",
      "Handling missing data for 'drink' with 2 missing values.\n",
      "After runNullFixer missing values in 'drink': 0\n",
      "\n",
      "Handling missing data for 'eating_changes' with 3 missing values.\n",
      "After runNullFixer missing values in 'eating_changes': 0\n",
      "\n",
      "Handling missing data for 'employment' with 9 missing values.\n",
      "After runNullFixer missing values in 'employment': 0\n",
      "\n",
      "Handling missing data for 'father_education' with 1 missing values.\n",
      "After runNullFixer missing values in 'father_education': 0\n",
      "\n",
      "Handling missing data for 'father_profession' with 3 missing values.\n",
      "After runNullFixer missing values in 'father_profession': 0\n",
      "\n",
      "Handling missing data for 'fav_cuisine' with 2 missing values.\n",
      "After runNullFixer missing values in 'fav_cuisine': 0\n",
      "\n",
      "Handling missing data for 'fav_food' with 2 missing values.\n",
      "After runNullFixer missing values in 'fav_food': 0\n",
      "\n",
      "Handling missing data for 'food_childhood' with 1 missing values.\n",
      "After runNullFixer missing values in 'food_childhood': 0\n",
      "\n",
      "Handling missing data for 'healthy_meal' with 1 missing values.\n",
      "After runNullFixer missing values in 'healthy_meal': 0\n",
      "\n",
      "Handling missing data for 'ideal_diet' with 1 missing values.\n",
      "After runNullFixer missing values in 'ideal_diet': 0\n",
      "\n",
      "Handling missing data for 'income' with 1 missing values.\n",
      "After runNullFixer missing values in 'income': 0\n",
      "\n",
      "Handling missing data for 'life_rewarding' with 1 missing values.\n",
      "After runNullFixer missing values in 'life_rewarding': 0\n",
      "\n",
      "Handling missing data for 'marital_status' with 1 missing values.\n",
      "After runNullFixer missing values in 'marital_status': 0\n",
      "\n",
      "Handling missing data for 'meals_dinner_friend' with 3 missing values.\n",
      "After runNullFixer missing values in 'meals_dinner_friend': 0\n",
      "\n",
      "Handling missing data for 'mother_education' with 3 missing values.\n",
      "After runNullFixer missing values in 'mother_education': 0\n",
      "\n",
      "Handling missing data for 'mother_profession' with 2 missing values.\n",
      "After runNullFixer missing values in 'mother_profession': 0\n",
      "\n",
      "Handling missing data for 'on_off_campus' with 1 missing values.\n",
      "After runNullFixer missing values in 'on_off_campus': 0\n",
      "\n",
      "Handling missing data for 'persian_food' with 1 missing values.\n",
      "After runNullFixer missing values in 'persian_food': 0\n",
      "\n",
      "Handling missing data for 'self_perception_weight' with 1 missing values.\n",
      "After runNullFixer missing values in 'self_perception_weight': 0\n",
      "\n",
      "Handling missing data for 'soup' with 1 missing values.\n",
      "After runNullFixer missing values in 'soup': 0\n",
      "\n",
      "Handling missing data for 'sports' with 2 missing values.\n",
      "After runNullFixer missing values in 'sports': 0\n",
      "\n",
      "Handling missing data for 'tortilla_calories' with 1 missing values.\n",
      "After runNullFixer missing values in 'tortilla_calories': 0\n",
      "\n",
      "Handling missing data for 'weight' with 0 missing values.\n",
      "After runNullFixer missing values in 'weight': 0\n"
     ]
    }
   ],
   "source": [
    "# run the iterator function to replace nulls in categorical columns with the mode\n",
    "# only replaces columns with count(missing_values) <= 12 (10% of the 125 row set)\n",
    "# selects a mode at random if count(modes) > 1\n",
    "runNullFixer(food, FAST_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuisine        17\n",
      "exercise       13\n",
      "type_sports    26\n"
     ]
    }
   ],
   "source": [
    "# show missing data, after each cell below rerun this 'to do list'\n",
    "missing_data = food.isnull().sum()\n",
    "show_missing = missing_data[missing_data > 0]\n",
    "print(show_missing.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: comfort_food_reasons_coded\n",
      "Data type: float64\n",
      "Unique values: [9. 1. 2. 4. 3. 7. 6. 5. 8.]\n",
      "\n",
      "Column: cuisine\n",
      "Data type: float64\n",
      "Unique values: [nan  1.  3.  2.  6.  4.  5.]\n",
      "\n",
      "Column: exercise\n",
      "Data type: float64\n",
      "Unique values: [ 1.  2.  3. nan]\n",
      "\n",
      "Column: type_sports\n",
      "Data type: object\n",
      "Unique values: ['car racing' 'Basketball ' 'none' nan 'Softball' 'None.' 'soccer'\n",
      " 'field hockey' 'Running' 'Soccer and basketball ' 'intramural volleyball'\n",
      " 'Hockey' 'hockey' 'dancing ' 'basketball' 'Soccer' 'Tennis'\n",
      " 'tennis soccer gym' 'Gaelic Football' 'Ice hockey' 'Lacrosse '\n",
      " 'snowboarding' 'none organized' 'softball' 'Lacrosse' 'Softball '\n",
      " 'Dancing' 'wrestling ' 'no particular engagement ' 'Volleyball' 'soccer '\n",
      " 'wrestling & rowing' 'Wrestling' 'Skiing' 'skiing '\n",
      " 'Water polo and running ' 'Ice Hockey' 'rowing ' 'tennis  '\n",
      " 'Recreational Basketball, Equestrian Team' 'Rec Volleyball' 'baseball'\n",
      " 'I danced in high school' 'horse back riding' 'competitive skiing'\n",
      " 'Rowing, Running, and Cycling' 'softball and basketball' 'wrestling'\n",
      " 'Marching Band' 'Collegiate Water Polo' 'None right now'\n",
      " 'volleyball, lacrosse' 'none ' 'Fotball' 'crew'\n",
      " 'Football, Basketball, Volleyball, Golf' 'hockey, soccer, golf'\n",
      " 'Running ' 'Volleyball, Track'\n",
      " 'When I can, rarely though play pool, darts, and basketball.'\n",
      " 'None at the moment' 'volleyball' 'I used to play softball ' ' None'\n",
      " 'Tennis, Basketball' \"No, I don't play sport.\" 'basketball ']\n"
     ]
    }
   ],
   "source": [
    "# column check\n",
    "check = ['comfort_food_reasons_coded', 'cuisine', 'exercise', 'type_sports']\n",
    "\n",
    "for column in check:\n",
    "    print(f\"\\nColumn: {column}\")\n",
    "    print(f\"Data type: {food[column].dtype}\")\n",
    "    print(f\"Unique values: {food[column].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">For cuisine, exercise and type_sports I am going to just select a value from the dataset at random. I'm doing this because there is >10% missing data for those columns and just adding the mode to all of them seems like it will introduce more bias than random sampling. </span> <br>\n",
    "<span style=\"color:red\">For comfort_food_reasons_coded I'm going to have to actually put in the correct data. Which I will do earlier in the process<br>coded: RETROFIX ... CORRECTION: We are doing text analysis on those columns so I will merely clean the data in RETROFIX</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values for 'type_sports': ['car racing' 'Basketball ' 'none' 'Softball' 'None.' 'soccer'\n",
      " 'field hockey' 'Running' 'Soccer and basketball ' 'intramural volleyball'\n",
      " 'Hockey' 'hockey' 'dancing ' 'basketball' 'Soccer' 'Tennis'\n",
      " 'tennis soccer gym' 'Gaelic Football' 'Ice hockey' 'Lacrosse '\n",
      " 'snowboarding' 'none organized' 'softball' 'Lacrosse' 'Softball '\n",
      " 'Dancing' 'wrestling ' 'no particular engagement ' 'Volleyball' 'soccer '\n",
      " 'wrestling & rowing' 'Wrestling' 'Skiing' 'skiing '\n",
      " 'Water polo and running ' 'Ice Hockey' 'rowing ' 'tennis  '\n",
      " 'Recreational Basketball, Equestrian Team' 'Rec Volleyball' 'baseball'\n",
      " 'I danced in high school' 'horse back riding' 'competitive skiing'\n",
      " 'Rowing, Running, and Cycling' 'softball and basketball' 'wrestling'\n",
      " 'Marching Band' 'Collegiate Water Polo' 'None right now'\n",
      " 'volleyball, lacrosse' 'none ' 'Fotball' 'crew'\n",
      " 'Football, Basketball, Volleyball, Golf' 'hockey, soccer, golf'\n",
      " 'Running ' 'Volleyball, Track'\n",
      " 'When I can, rarely though play pool, darts, and basketball.'\n",
      " 'None at the moment' 'volleyball' 'I used to play softball ' ' None'\n",
      " 'Tennis, Basketball' \"No, I don't play sport.\" 'basketball ']\n",
      "Row 3, Column 'type_sports' filled with value: baseball\n",
      "Row 16, Column 'type_sports' filled with value: soccer \n",
      "Row 28, Column 'type_sports' filled with value: Marching Band\n",
      "Row 29, Column 'type_sports' filled with value: Running\n",
      "Row 33, Column 'type_sports' filled with value: tennis soccer gym\n",
      "Row 41, Column 'type_sports' filled with value: Running \n",
      "Row 42, Column 'type_sports' filled with value: None at the moment\n",
      "Row 50, Column 'type_sports' filled with value: no particular engagement \n",
      "Row 53, Column 'type_sports' filled with value: wrestling & rowing\n",
      "Row 61, Column 'type_sports' filled with value: Rowing, Running, and Cycling\n",
      "Row 65, Column 'type_sports' filled with value: Softball \n",
      "Row 69, Column 'type_sports' filled with value: Fotball\n",
      "Row 72, Column 'type_sports' filled with value: Ice hockey\n",
      "Row 74, Column 'type_sports' filled with value: Fotball\n",
      "Row 80, Column 'type_sports' filled with value: Running \n",
      "Row 88, Column 'type_sports' filled with value: none \n",
      "Row 93, Column 'type_sports' filled with value: wrestling \n",
      "Row 101, Column 'type_sports' filled with value: Lacrosse\n",
      "Row 102, Column 'type_sports' filled with value: Volleyball\n",
      "Row 106, Column 'type_sports' filled with value: Lacrosse \n",
      "Row 111, Column 'type_sports' filled with value: Running\n",
      "Row 112, Column 'type_sports' filled with value: When I can, rarely though play pool, darts, and basketball.\n",
      "Row 113, Column 'type_sports' filled with value: Marching Band\n",
      "Row 118, Column 'type_sports' filled with value: field hockey\n",
      "Row 123, Column 'type_sports' filled with value: softball\n",
      "Row 124, Column 'type_sports' filled with value: None right now\n",
      "Missing values in 'type_sports' after random_replace: 0\n",
      "Unique values for 'cuisine': [1. 3. 2. 6. 4. 5.]\n",
      "Row 0, Column 'cuisine' filled with value: 6.0\n",
      "Row 5, Column 'cuisine' filled with value: 5.0\n",
      "Row 16, Column 'cuisine' filled with value: 3.0\n",
      "Row 29, Column 'cuisine' filled with value: 3.0\n",
      "Row 32, Column 'cuisine' filled with value: 4.0\n",
      "Row 36, Column 'cuisine' filled with value: 2.0\n",
      "Row 55, Column 'cuisine' filled with value: 2.0\n",
      "Row 61, Column 'cuisine' filled with value: 3.0\n",
      "Row 69, Column 'cuisine' filled with value: 6.0\n",
      "Row 89, Column 'cuisine' filled with value: 2.0\n",
      "Row 90, Column 'cuisine' filled with value: 3.0\n",
      "Row 94, Column 'cuisine' filled with value: 4.0\n",
      "Row 106, Column 'cuisine' filled with value: 2.0\n",
      "Row 111, Column 'cuisine' filled with value: 1.0\n",
      "Row 116, Column 'cuisine' filled with value: 5.0\n",
      "Row 121, Column 'cuisine' filled with value: 3.0\n",
      "Row 122, Column 'cuisine' filled with value: 6.0\n",
      "Missing values in 'cuisine' after random_replace: 0\n",
      "Unique values for 'exercise': [1. 2. 3.]\n",
      "Row 8, Column 'exercise' filled with value: 1.0\n",
      "Row 24, Column 'exercise' filled with value: 2.0\n",
      "Row 32, Column 'exercise' filled with value: 2.0\n",
      "Row 42, Column 'exercise' filled with value: 2.0\n",
      "Row 43, Column 'exercise' filled with value: 1.0\n",
      "Row 45, Column 'exercise' filled with value: 3.0\n",
      "Row 53, Column 'exercise' filled with value: 2.0\n",
      "Row 59, Column 'exercise' filled with value: 3.0\n",
      "Row 66, Column 'exercise' filled with value: 1.0\n",
      "Row 83, Column 'exercise' filled with value: 3.0\n",
      "Row 99, Column 'exercise' filled with value: 3.0\n",
      "Row 104, Column 'exercise' filled with value: 2.0\n",
      "Row 117, Column 'exercise' filled with value: 1.0\n",
      "Missing values in 'exercise' after random_replace: 0\n"
     ]
    }
   ],
   "source": [
    "random_replace = ['type_sports', 'cuisine', 'exercise']\n",
    "\n",
    "for column in random_replace:\n",
    "\n",
    "    print(f\"Unique values for '{column}': {food[column].dropna().unique()}\")\n",
    "    \n",
    "    # create a list of unique values\n",
    "    unique = food[column].dropna().unique().tolist()\n",
    "    \n",
    "    # iterate through each row and fill missing values with a random selection\n",
    "    for index, row in food.iterrows():\n",
    "\n",
    "        if pd.isnull(row[column]): # thanks murach's\n",
    "            selected = random.choice(unique)\n",
    "            food.at[index, column] = selected\n",
    "            print(f\"Row {index}, Column '{column}' filled with value: {selected}\")\n",
    "    \n",
    "    # Print the last value (number of remaining missing values) should be '0'\n",
    "    print(f\"Missing values in '{column}' after random_replace: {food[column].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Now I'm seeing all the goofy sports inputs...</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">I used Chat GPT to generate the mapping object by dumping the unique value list into it and explaining it the rules I wanted, then I had to edit the code a little (a lot for Multi) bit.</span><br>\n",
    "QUERY: I am doing data analysis in python with jupyter notebooks. my dataset is related to cafeteria at a college. these are the 'type_sports' unique values in my data set. I need to split this down into categories, and use the 'None' category to catch all the inputs that mean that, and use a 'Multi' category to catch all the inputs with multiple sports listed. then i need to do this type of thing: intramural volleyball, Rec Volleyball, should both be Volleyball (same for other inputs that mean the same thing...) Unique values for 'type_sports': (copy and pasted from results above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated unique values for 'type_sports': ['NoSport' 'Baseball' 'Softball' 'Soccer' 'Running' 'Multi' 'Volleyball'\n",
      " 'Hockey' 'Basketball' 'Tennis' 'GaelicFootball' 'Lacrosse' 'MarchingBand'\n",
      " 'Snowboarding' 'Dancing' 'Wrestling' 'Skiing' 'Football' 'HorseRiding'\n",
      " 'WaterPolo']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\AppData\\Local\\Temp\\ipykernel_25984\\2059734519.py:51: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  food['type_sports'].fillna('NoSport', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#CHAT GPT OBJECT/FUNCTION\n",
    "single_sport_mapping = {\n",
    "    'Volleyball': ['intramural volleyball', 'Rec Volleyball', 'volleyball'],\n",
    "    'Basketball': ['Basketball ', 'basketball'],\n",
    "    'Soccer': ['soccer', 'Soccer', 'soccer '],\n",
    "    'Hockey': ['Hockey', 'hockey', 'Ice hockey', 'Ice Hockey'],\n",
    "    'Softball': ['Softball', 'softball', 'Softball '],\n",
    "    'Tennis': ['Tennis', 'tennis'],\n",
    "    'Running': ['Running', 'Running '],\n",
    "    'Dancing': ['dancing ', 'Dancing'],\n",
    "    'Wrestling': ['wrestling ', 'Wrestling'],\n",
    "    'Lacrosse': ['Lacrosse ', 'Lacrosse'],\n",
    "    'Skiing': ['Skiing', 'competitive skiing', 'skiing '],\n",
    "    'Football': ['Football', 'Fotball'],\n",
    "    'Golf': ['Golf'],\n",
    "    'Rowing': ['rowing ', 'Rowing'],\n",
    "    'GaelicFootball': ['Gaelic Football'],\n",
    "    'Baseball': ['baseball'],\n",
    "    'Snowboarding': ['snowboarding'],\n",
    "    'WaterPolo': ['Collegiate Water Polo'],\n",
    "    'HorseRiding': ['horse back riding'],\n",
    "    'MarchingBand': ['Marching Band'],\n",
    "    'NoSport': [\n",
    "        'none', 'no particular engagement', 'none organized', 'none ', 'None', 'I danced in high school', 'Missing'\n",
    "        'None right now', 'None at the moment', 'When I can, rarely though play pool, darts, and basketball.', 'None.'\n",
    "    ],\n",
    "    'Multi': [\n",
    "        'Soccer and basketball', 'softball and basketball', 'soccer and basketball', 'Rowing, Running, and Cycling', \n",
    "        'Water polo and running', 'Recreational Basketball, Equestrian Team', 'wrestling & rowing', 'volleyball, lacrosse', \n",
    "        'Football, Basketball, Volleyball, Golf', 'hockey, soccer, golf', 'tennis soccer gym','rowing, running', \n",
    "    ]\n",
    "}\n",
    "\n",
    "def categorize_sport(value):\n",
    "\n",
    "    value = value.strip()  \n",
    "    \n",
    "    for category, items in single_sport_mapping.items():\n",
    "        if value in items:\n",
    "            return category\n",
    "        \n",
    "    if pd.isna(value) or not isinstance(value, str):\n",
    "        return 'NoSport'\n",
    "        \n",
    "    return 'NoSport'\n",
    "\n",
    "food['type_sports'] = food['type_sports'].apply(categorize_sport)\n",
    "\n",
    "# had a hard time getting rid of NaN values...then I vaguely remember something like this in R, where changes to NaN dont carry over when you export\n",
    "# wondered if it was the same here, and just replaced missing values in the analysis.\n",
    "food['type_sports'].fillna('NoSport', inplace=True)\n",
    "\n",
    "print(f\"Updated unique values for 'type_sports': {food['type_sports'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining null values: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpa</th>\n",
       "      <th>gender</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>calories_chicken</th>\n",
       "      <th>calories_day</th>\n",
       "      <th>calories_scone</th>\n",
       "      <th>coffee</th>\n",
       "      <th>comfort_food</th>\n",
       "      <th>comfort_food_reasons</th>\n",
       "      <th>comfort_food_reasons_coded</th>\n",
       "      <th>...</th>\n",
       "      <th>soup</th>\n",
       "      <th>sports</th>\n",
       "      <th>thai_food</th>\n",
       "      <th>tortilla_calories</th>\n",
       "      <th>turkey_calories</th>\n",
       "      <th>type_sports</th>\n",
       "      <th>veggies_day</th>\n",
       "      <th>vitamins</th>\n",
       "      <th>waffle_calories</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.400</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>3.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>we dont have comfort</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>345</td>\n",
       "      <td>NoSport</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.654</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>610</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>chocolate, chips, ice cream</td>\n",
       "      <td>Stress, bored, anger</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>725.0</td>\n",
       "      <td>690</td>\n",
       "      <td>NoSport</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>900</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>4.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>frozen yogurt, pizza, fast food</td>\n",
       "      <td>stress, sadness</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>500</td>\n",
       "      <td>NoSport</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>900</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.200</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>430</td>\n",
       "      <td>3.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Pizza, Mac and cheese, ice cream</td>\n",
       "      <td>Boredom</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>725.0</td>\n",
       "      <td>690</td>\n",
       "      <td>Baseball</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1315</td>\n",
       "      <td>155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>2.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ice cream, chocolate, chips</td>\n",
       "      <td>Stress, boredom, cravings</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>940.0</td>\n",
       "      <td>500</td>\n",
       "      <td>Softball</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>760</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gpa  gender  breakfast  calories_chicken  calories_day  calories_scone  \\\n",
       "0  2.400       2          1               430           3.0           315.0   \n",
       "1  3.654       1          1               610           3.0           420.0   \n",
       "2  3.300       1          1               720           4.0           420.0   \n",
       "3  3.200       1          1               430           3.0           420.0   \n",
       "4  3.500       1          1               720           2.0           420.0   \n",
       "\n",
       "   coffee                      comfort_food        comfort_food_reasons  \\\n",
       "0       1                              none       we dont have comfort    \n",
       "1       2       chocolate, chips, ice cream        Stress, bored, anger   \n",
       "2       2   frozen yogurt, pizza, fast food             stress, sadness   \n",
       "3       2  Pizza, Mac and cheese, ice cream                     Boredom   \n",
       "4       2      Ice cream, chocolate, chips   Stress, boredom, cravings    \n",
       "\n",
       "   comfort_food_reasons_coded  ...  soup  sports  thai_food tortilla_calories  \\\n",
       "0                         9.0  ...   1.0     1.0          1            1165.0   \n",
       "1                         1.0  ...   1.0     1.0          2             725.0   \n",
       "2                         1.0  ...   1.0     2.0          5            1165.0   \n",
       "3                         2.0  ...   1.0     2.0          5             725.0   \n",
       "4                         1.0  ...   1.0     1.0          4             940.0   \n",
       "\n",
       "   turkey_calories  type_sports veggies_day  vitamins  waffle_calories  weight  \n",
       "0              345      NoSport           5         1             1315   187.0  \n",
       "1              690      NoSport           4         2              900   155.0  \n",
       "2              500      NoSport           5         1              900   155.0  \n",
       "3              690     Baseball           3         1             1315   155.0  \n",
       "4              500     Softball           4         2              760   190.0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Remaining null values: {food['type_sports'].isna().sum()}\")\n",
    "food.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green\">I am happy with the type_sports values.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in 'cuisine' column: 0\n",
      "Unique values in 'cuisine' column: [6. 1. 3. 2. 5. 4.]\n",
      "Value counts for 'cuisine' column:\n",
      "cuisine\n",
      "1.0    87\n",
      "2.0    17\n",
      "3.0     8\n",
      "6.0     5\n",
      "4.0     5\n",
      "5.0     3\n",
      "Name: count, dtype: int64\n",
      "Data type of 'cuisine' column: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the 'cuisine' column\n",
    "missing_values = food['cuisine'].isnull().sum()\n",
    "print(f\"Missing values in 'cuisine' column: {missing_values}\")\n",
    "\n",
    "# Check unique values in the 'cuisine' column\n",
    "unique_values = food['cuisine'].unique()\n",
    "print(f\"Unique values in 'cuisine' column: {unique_values}\")\n",
    "\n",
    "# Count the occurrences of each unique value in the 'cuisine' column\n",
    "cuisine_counts = food['cuisine'].value_counts()\n",
    "print(f\"Value counts for 'cuisine' column:\\n{cuisine_counts}\")\n",
    "\n",
    "# Convert 'cuisine' column to integer\n",
    "food['cuisine'] = food['cuisine'].astype(int)\n",
    "data_type = food['cuisine'].dtype\n",
    "print(f\"Data type of 'cuisine' column: {data_type}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Cleaned Report and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total null values in the 'food' dataframe: 0\n"
     ]
    }
   ],
   "source": [
    "# check total nulls in food dataframe # had to research how to achieve the results of .sum().sum()\n",
    "total_null = food.isnull().sum().sum() \n",
    "print(f\"Total null values in the 'food' dataframe: {total_null}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the dataset\n",
    "descript = food.describe()\n",
    "shape = food.shape\n",
    "columns = food.columns\n",
    "nulls = food.isnull().sum()\n",
    "\n",
    "# had to look up had to handle the response from .info\n",
    "buffer = io.StringIO()\n",
    "food.info(buf=buffer)\n",
    "info = buffer.getvalue()\n",
    "\n",
    "# generate a report from the `explore the dataset` cell\n",
    "name = 'clean'\n",
    "file_name = produceReport(shape, columns, info, descript, nulls, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "food.to_csv(CLEAN_FILE_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
